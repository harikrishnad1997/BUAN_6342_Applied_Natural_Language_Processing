{"cells":[{"cell_type":"markdown","id":"Q4vVUgxxDJD0","metadata":{"id":"Q4vVUgxxDJD0"},"source":["# <font color = dodgerred>**HW1 - 15 Points** </font>\n","- **You have to submit two files for this part of the HW**\n","  >(1) ipynb (colab notebook) and<br>\n","  >(2) pdf file (pdf version of the colab file).**\n","- **Files should be named as follows**:\n",">FirstName_LastName_HW_1**\n"]},{"cell_type":"code","execution_count":null,"id":"IsWkg1CufBwg","metadata":{"id":"IsWkg1CufBwg"},"outputs":[],"source":["import torch\n","import time"]},{"cell_type":"markdown","id":"2Voz6l5RUZRh","metadata":{"id":"2Voz6l5RUZRh"},"source":["# <font color = dodgerred>**Q1 : Create Tensor (1/2 Point)**\n"," Create a torch Tensor of shape (5, 3) which is filled with zeros. Modify the tensor to set element (0, 2) to 10 and element (2, 0)  to 100."]},{"cell_type":"code","execution_count":null,"id":"bI9MwTaamhis","metadata":{"id":"bI9MwTaamhis"},"outputs":[],"source":["my_tensor = torch.zeros(5, 3)"]},{"cell_type":"code","execution_count":null,"id":"7QEV2uq-yqZK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706462071505,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"7QEV2uq-yqZK","outputId":"2bcc79ed-b230-4cc7-9b04-7742f4d7ce8b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 3])"]},"metadata":{},"execution_count":3}],"source":["my_tensor.shape"]},{"cell_type":"code","execution_count":null,"id":"yAxzhRVGyr6c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1706462071639,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"yAxzhRVGyr6c","outputId":"b2f5cbe7-3300-4a24-c318-8b4978bab62e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])"]},"metadata":{},"execution_count":4}],"source":["my_tensor"]},{"cell_type":"code","execution_count":null,"id":"FCM4GuyWylQV","metadata":{"id":"FCM4GuyWylQV"},"outputs":[],"source":["# Manually set the value at the first row and third column to 10,\n","# and the value at the third row and first column to 100 in the tensor named \"my_tensor\".\n","\n","my_tensor[0, 2] = 10\n","my_tensor[2, 0] = 100"]},{"cell_type":"code","execution_count":null,"id":"ZdEftwuPyyx9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1706462071798,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"ZdEftwuPyyx9","outputId":"7b7e439b-4350-4197-9f83-58e09fb7e366"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  0.,   0.,  10.],\n","        [  0.,   0.,   0.],\n","        [100.,   0.,   0.],\n","        [  0.,   0.,   0.],\n","        [  0.,   0.,   0.]])"]},"metadata":{},"execution_count":6}],"source":["my_tensor"]},{"cell_type":"markdown","id":"6Eoa6rF80ZTa","metadata":{"id":"6Eoa6rF80ZTa"},"source":["# <font color = dodgerred>**Q2: Reshape tensor (1/2 Point)**\n","You have following tensor as input:\n","\n","```x=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])```\n","\n","Using only reshaping functions (like view, reshape, transpose, permute), you need to get at the following tensor as output:\n","\n","```\n","tensor([[ 0,  4,  8, 12, 16, 20],\n","        [ 1,  5,  9, 13, 17, 21],\n","        [ 2,  6, 10, 14, 18, 22],\n","        [ 3,  7, 11, 15, 19, 23]])\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"id":"LDBQ6kYZ-JRV","metadata":{"id":"LDBQ6kYZ-JRV"},"outputs":[],"source":["x=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])"]},{"cell_type":"code","execution_count":null,"id":"b6_SdFS-ke_x","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1706462071799,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"b6_SdFS-ke_x","outputId":"768a4b5e-3f33-48cb-bc81-f861060a58b3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  4,  8, 12, 16, 20],\n","        [ 1,  5,  9, 13, 17, 21],\n","        [ 2,  6, 10, 14, 18, 22],\n","        [ 3,  7, 11, 15, 19, 23]])"]},"metadata":{},"execution_count":8}],"source":["x = x.view(6, 4).transpose(0,1)\n","x"]},{"cell_type":"markdown","id":"dnw5qi7A4ysc","metadata":{"id":"dnw5qi7A4ysc"},"source":["# <font color = dodgerred>**Q3: Slice tensor (1Point)**\n","\n","- Slice the tensor x to get the following\n",">- last row of x\n",">- fourth column of x\n",">- first three rows and first two columns - the shape of subtensor should be (3,2)\n",">- odd valued rows and columns"]},{"cell_type":"code","execution_count":null,"id":"STbUdF0J5IBD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706462071799,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"STbUdF0J5IBD","outputId":"05e8ddbe-3cf9-44e3-9ffc-027f8b980de9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  8, 10],\n","        [11, 12, 13, 14, 15]])"]},"metadata":{},"execution_count":9}],"source":["x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 8, 10], [11, 12, 13, 14, 15]])\n","x"]},{"cell_type":"code","execution_count":null,"id":"mgHPm0qP5ZU3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706462071799,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"mgHPm0qP5ZU3","outputId":"ac8e7a01-c4e3-436e-ee8c-b847de16751b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 5])"]},"metadata":{},"execution_count":10}],"source":["x.shape"]},{"cell_type":"code","execution_count":null,"id":"hzQRs79A5JGd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706462071799,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"hzQRs79A5JGd","outputId":"98c40bd1-80d9-4565-e3f6-a95a28ae170b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([11, 12, 13, 14, 15])"]},"metadata":{},"execution_count":11}],"source":["# Student Task: Retrieve the last row of the tensor 'x'\n","# Hint: Negative indexing can help you select rows or columns counting from the end of the tensor.\n","# Think about how you can select all columns for the desired row.\n","last_row = x[-1, :]\n","last_row"]},{"cell_type":"code","execution_count":null,"id":"-mb_Et866ZEW","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706462071799,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"-mb_Et866ZEW","outputId":"819e87fc-bfcf-455b-a1b6-d5afc8417557"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 4,  8, 14])"]},"metadata":{},"execution_count":12}],"source":["# Student Task: Retrieve the fourth column of the tensor 'x'\n","# Hint: Pay attention to the indexing for both rows and columns.\n","# Remember that indexing in Python starts from zero.\n","fourth_column = x[:, 3]\n","fourth_column"]},{"cell_type":"code","execution_count":null,"id":"c2VaG6Y16jsA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706462071799,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"c2VaG6Y16jsA","outputId":"f279b761-5f41-4231-be9e-b1c65cfc00bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1,  2],\n","        [ 6,  7],\n","        [11, 12]])"]},"metadata":{},"execution_count":13}],"source":["# Student Task: Retrieve the first 3 rows and first 2 columns from the tensor 'x'.\n","# Hint: Use slicing to extract the required subset of rows and columns.\n","first_3_rows_2_columns = x[:3, :2]\n","first_3_rows_2_columns"]},{"cell_type":"code","execution_count":null,"id":"RHnSUpxs7O82","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1706462071933,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"RHnSUpxs7O82","outputId":"3923b696-435c-449c-8ca3-2055fa13f00d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1,  3,  5],\n","        [11, 13, 15]])"]},"metadata":{},"execution_count":14}],"source":["# Student Task: Retrieve the rows and columns with odd-indexed positions from the tensor 'x'.\n","# Hint: Use stride slicing to extract the required subset of rows and columns with odd indices.\n","odd_valued_rows_columns = x[::2, ::2]\n","odd_valued_rows_columns"]},{"cell_type":"markdown","id":"uSj20OEuf6bf","metadata":{"id":"uSj20OEuf6bf"},"source":["#  <font color = dodgerred>**Q4 -Normalize Function (1/2 Points)**<font>\n","\n","Write the function that normalizes the columns of a matrix. You have to compute the mean and standard deviation of each column. Then for each element of the column, you subtract the mean and divide by the standard deviation."]},{"cell_type":"code","execution_count":null,"id":"8L9JBFNilkWt","metadata":{"id":"8L9JBFNilkWt"},"outputs":[],"source":["# Given Data\n","x = [[ 3,  60,  100, -100],\n","     [ 2,  20,  600, -600],\n","     [-5,  50,  900, -900]]"]},{"cell_type":"code","execution_count":null,"id":"iRrhopVBl-0q","metadata":{"id":"iRrhopVBl-0q"},"outputs":[],"source":["# Convert to PyTorch Tensor and set to float\n","X = torch.tensor(x)\n","X= X.float()"]},{"cell_type":"code","execution_count":null,"id":"S2MaocHxmEQJ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1706462071934,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"S2MaocHxmEQJ","outputId":"9777a527-94a6-4235-fa03-05f22fd4360f"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 4])\n","torch.float32\n"]}],"source":["# Print shape and data type for verification\n","print(X.shape)\n","print(X.dtype)"]},{"cell_type":"code","execution_count":null,"id":"rPgb1L9RmQAU","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1706462071934,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"rPgb1L9RmQAU","outputId":"74b242b0-9d49-4d74-d454-776291fced94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  4.3589,  20.8167, 404.1452, 404.1452])"]},"metadata":{},"execution_count":18}],"source":["# Compute and display the mean and standard deviation of each column for reference\n","X.mean(axis = 0)\n","X.std(axis = 0)"]},{"cell_type":"code","execution_count":null,"id":"qnM87Db1mqFH","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1706462071934,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"qnM87Db1mqFH","outputId":"3a5db143-057b-48e0-d1fe-6c1875ca5b98"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  4.3589,  20.8167, 404.1452, 404.1452])"]},"metadata":{},"execution_count":19}],"source":["X.std(axis = 0)"]},{"cell_type":"markdown","source":["- Your task starts here\n","- Your normalize_matrix function should take a PyTorch tensor x as input.\n","- It should return a tensor where the columns are normalized.\n","- After implementing your function, use the code provided to verify if the mean for each column in Z is close to zero and the standard deviation is 1."],"metadata":{"id":"Yy2hehDnJHOq"},"id":"Yy2hehDnJHOq"},{"cell_type":"code","execution_count":null,"id":"mwq8qnqFlu9V","metadata":{"id":"mwq8qnqFlu9V"},"outputs":[],"source":["def normalize_matrix(x):\n","  # Calculate the mean along each column (think carefully , you will take mean along axis = 0 or 1)\n","  mean = torch.mean(x, dim=0)\n","\n","  # Calculate the standard deviation along each column\n","  std = torch.std(x, dim=0)\n","\n","  # Normalize each element in the columns by subtracting the mean and dividing by the standard deviation\n","  y = (x - mean) / std\n","\n","  return y  # Return the normalized matrix\n","\n"]},{"cell_type":"code","execution_count":null,"id":"m027Qcgwm9OL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1706462071934,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"m027Qcgwm9OL","outputId":"2f521202-abd7-4312-942a-92375a244cfa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.6882,  0.8006, -1.0722,  1.0722],\n","        [ 0.4588, -1.1209,  0.1650, -0.1650],\n","        [-1.1471,  0.3203,  0.9073, -0.9073]])"]},"metadata":{},"execution_count":21}],"source":["Z = normalize_matrix(X)\n","Z"]},{"cell_type":"code","execution_count":null,"id":"78-0D3KfnHel","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1706462071934,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"},"user_tz":360},"id":"78-0D3KfnHel","outputId":"c5bfc7b6-6eba-4511-ab66-0a9f5a0d4a76"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.0000e+00,  4.9671e-08,  3.9736e-08, -3.9736e-08])"]},"metadata":{},"execution_count":22}],"source":["Z.mean(axis = 0)"]},{"cell_type":"markdown","metadata":{"id":"cc32848b"},"source":["# <font color = 'dodgerred'>**Q5: In-place vs. Out-of-place Operations (1 Point)**\n","\n","1. Create a tensor `A` with values `[1, 2, 3]`.\n","2. Perform an in-place addition (use `add_` method) of `5` to tensor `A`.\n","3. Then, create another tensor `B` with values `[4, 5, 6]` and perform an out-of-place addition of `5`.\n","\n","**Print the memory addresses of `A` and `B` before and after the operations to demonstrate the difference in memory usage. Provide explanation**\n"],"id":"cc32848b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"19b3aaa5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462071934,"user_tz":360,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"7ef4e39a-3c77-4722-a9df-72cced6ba375"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original memory address of A: 133329084446288\n","Memory address of A after in-place addition: 133329084446288\n","A after in-place addition: tensor([6, 7, 8])\n","Original memory address of B: 133329082926240\n","Memory address of B after out-of-place addition: 133329082927440\n","B after out-of-place addition: tensor([ 9, 10, 11])\n"]}],"source":["A = torch.tensor([1, 2, 3])\n","print('Original memory address of A:', id(A))\n","A.add_(5)\n","print('Memory address of A after in-place addition:', id(A))\n","print('A after in-place addition:', A)\n","\n","B = torch.tensor([4, 5, 6])\n","print('Original memory address of B:', id(B))\n","B = B + 5\n","print('Memory address of B after out-of-place addition:', id(B))\n","print('B after out-of-place addition:', B)\n"],"id":"19b3aaa5"},{"cell_type":"markdown","source":["**Provide Explanation for above question here :**\n","\n","A is a in place operation. This ensures memory address of the tensor remains the same and helps with memory allocation.\n","\n","B is being created again and assigned the same variable name. Therefore, each time B is created it is alloted a new address.\n"],"metadata":{"id":"aXi2TsYVElqy"},"id":"aXi2TsYVElqy"},{"cell_type":"markdown","metadata":{"id":"f57bb1a4"},"source":["# <font color = 'dodgerred'>**Q6: Tensor Broadcasting (1 Point)**\n","\n","1. Create two tensors `X` with shape `(3, 1)` and `Y` with shape `(1, 3)`. Perform an addition operation on `X` and `Y`.\n","2. Explain how broadcasting is applied in this operation by describing the shape changes that occur internally."],"id":"f57bb1a4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"699f9bd9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462071934,"user_tz":360,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"15a44ba4-915d-470a-90a6-c9bf8d56fb52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original shapes: torch.Size([3, 1]) torch.Size([1, 3])\n","tensor([[0.1459],\n","        [0.1199],\n","        [0.8207]])\n","tensor([[0.9270, 0.3545, 0.2465]])\n","Result: tensor([[1.0729, 0.5004, 0.3924],\n","        [1.0469, 0.4744, 0.3664],\n","        [1.7476, 1.1751, 1.0671]])\n","Result shape: torch.Size([3, 3])\n"]}],"source":["X = torch.rand((3, 1))\n","Y = torch.rand((1, 3))\n","print('Original shapes:', X.shape, Y.shape)\n","print(X)\n","print(Y)\n","result = X + Y\n","print('Result:', result)\n","print('Result shape:', result.shape)\n"],"id":"699f9bd9"},{"cell_type":"markdown","source":["**Provide Explanation for above question here :**\n","\n","Broadcasting enables the tensors X and Y to be of same shape and it used to perform the Tensor addition\n","\n","* PyTorch identifies compatible dimensions (here, the first dimension of X and the second dimension of Y have a size of 1).\n","* It virtually expands those dimensions to match each other, creating intermediate views of X and Y as if they both had a shape of (3, 3).\n","* This allows element-wise addition to proceed without explicit reshaping.\n","\n"],"metadata":{"id":"IblSVvPhE4-E"},"id":"IblSVvPhE4-E"},{"cell_type":"markdown","metadata":{"id":"e1f2667e"},"source":["# <font color = 'dodgerred'>**Q7: Linear Algebra Operations (1 Point)**\n","\n","1. Create two matrices `M1` and `M2` of compatible shapes for matrix multiplication. Perform the multiplication and print the result.\n","2. Then, create two vectors `V1` and `V2` and compute their dot product.\n"],"id":"e1f2667e"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d45aed18","executionInfo":{"status":"ok","timestamp":1706462071934,"user_tz":360,"elapsed":5,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"ab48eca0-0ba8-46f8-917c-8bb40cb3dca4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix multiplication result: tensor([[2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.]])\n","Dot product: tensor(3.)\n"]}],"source":["M1 = torch.ones(3,2)\n","M2 = torch.ones(2,3)\n","mat_multiplication =  torch.mm(M1,M2)\n","print('Matrix multiplication result:', mat_multiplication)\n","\n","V1 = torch.ones(3,)\n","V2 =  torch.ones(3,)\n","dot_product =  torch.dot(V1, V2)\n","print('Dot product:', dot_product)"],"id":"d45aed18"},{"cell_type":"markdown","metadata":{"id":"fe24a961"},"source":["# <font color = 'dodgerred'>**Q8: Manipulating Tensor Shapes (1 Point)**\n","\n","Given a tensor `T` with shape `(2, 3, 4)`, demonstrate how to\n","1. reshape it to `(3, 8)` using view,\n","2. reshape it to `(4, 2, 3` using reshape,\n","3. transpose the first and last dimensions using permute.\n","4. explain what is the difference between reshape and view"],"id":"fe24a961"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0644b861","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462071934,"user_tz":360,"elapsed":4,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"7b201294-b84f-491b-b9c8-0750483a00a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["T_view shape: torch.Size([3, 8])\n","T_reshape shape: torch.Size([4, 2, 3])\n","T_permute shape: torch.Size([4, 3, 2])\n"]}],"source":["T = torch.rand(2, 3, 4)\n","T_view =  T.view(3,8)\n","print('T_view shape:', T_view.shape)\n","\n","T_reshape =  T.reshape(4, 2, 3)\n","print('T_reshape shape:', T_reshape.shape)\n","\n","T_permute =  T.permute(2, 1, 0)\n","print('T_permute shape:', T_permute.shape)"],"id":"0644b861"},{"cell_type":"markdown","source":["**Provide Explanation for above question here :**\n","\n","View can be only used for contiguous tensor in contrary to reshape.\n","\n","\n","If you just want to reshape tensors, use torch.reshape. If you're also concerned about memory usage and want to ensure that the two tensors share the same data, use torch.view.\n","\n"],"metadata":{"id":"Lb-861xsFXHN"},"id":"Lb-861xsFXHN"},{"cell_type":"markdown","metadata":{"id":"1d5c7b62"},"source":["# <font color = 'dodgerred'>**Q9: Tensor Concatenation and Stacking (1 Point)**\n","\n","Create tensors `C1` and `C2` both with shape (2, 3).\n","1. Concatenate them along dimension 0 and then along dimension 1. Print the shape of the resulting tensor.\n","2. Afterwards, stack the same tensors alomng dimension 0  and print the shape of the resulting tensor.\n","3. What is the difference between stacking and concatinating."],"id":"1d5c7b62"},{"cell_type":"code","execution_count":null,"metadata":{"id":"69e2f7e0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462072131,"user_tz":360,"elapsed":200,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"db296ee2-21ef-4a1a-9376-1c7b716e2fe0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Concatenated along dimension 0: torch.Size([4, 3])\n","Concatenated along dimension 1: torch.Size([2, 6])\n","Stacked tensor shape: torch.Size([2, 2, 3])\n"]}],"source":["C1 = torch.rand(2, 3)\n","C2 = torch.rand(2, 3)\n","concatenated_dim0 =  torch.cat([C1, C2], dim=0)\n","print('Concatenated along dimension 0:', concatenated_dim0.shape)\n","\n","concatenated_dim1 =  torch.cat([C1, C2], dim=1)\n","print('Concatenated along dimension 1:', concatenated_dim1.shape)\n","\n","stacked =  torch.stack([C1, C2], dim=0)\n","print('Stacked tensor shape:', stacked.shape)\n"],"id":"69e2f7e0"},{"cell_type":"markdown","source":["**Explain the diffrence between concatinating and stacking here**\n","\n","Concatinating combines tensors along an existing dimnesion, whereas stacking adds a dimension and adds the tensors along that dimension.\n","\n"],"metadata":{"id":"kmKpP5xBCCgt"},"id":"kmKpP5xBCCgt"},{"cell_type":"markdown","metadata":{"id":"0d0ed971"},"source":["# <font color = 'dodgerred'>**Q10: Advanced Indexing and Slicing (1 Point)**\n","\n","1. Given a tensor `D` with shape (6, 6), extract elements that are greater than 0.5.\n","2. Then, extract the second and fourth rows from `D`.\n","3. Finally, extract a sub-tensor from the top-left 3x3 block."],"id":"0d0ed971"},{"cell_type":"code","execution_count":null,"metadata":{"id":"df969523","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462072132,"user_tz":360,"elapsed":7,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"45613e6c-be36-4dd8-8acb-b32e5edc5469"},"outputs":[{"output_type":"stream","name":"stdout","text":["Elements greater than 0.5:\n"," tensor([0.6884, 0.8273, 0.6424, 0.8448, 0.8425, 0.5156, 0.6234, 0.9275, 0.6874,\n","        0.6476, 0.8045, 0.6582, 0.8050, 0.9965, 0.6037, 0.6547, 0.9343])\n","\n","Second and fourth rows:\n"," tensor([[0.2232, 0.0988, 0.6424, 0.8448, 0.8425, 0.2920],\n","        [0.9275, 0.1603, 0.4000, 0.6874, 0.6476, 0.2764]])\n","\n","Top-left 3x3 block:\n","  tensor([[0.3689, 0.3303, 0.6884],\n","        [0.2232, 0.0988, 0.6424],\n","        [0.0851, 0.5156, 0.6234]])\n"]}],"source":["D = torch.rand(6, 6)\n","print('Elements greater than 0.5:\\n',  D[D > 0.5])\n","\n","second_fourth_rows =  D[[1, 3], :]\n","print('\\nSecond and fourth rows:\\n', second_fourth_rows)\n","\n","top_left_3x3 =  D[:3, :3]\n","print('\\nTop-left 3x3 block:\\n ', top_left_3x3)"],"id":"df969523"},{"cell_type":"markdown","metadata":{"id":"c081cf3b"},"source":["# <font color = 'dodgerred'>**Q11: Tensor Mathematical Operations (1 Point)**\n","\n","1. Create a tensor `G` with values from 0 to π in steps of π/4.\n","2. Compute and print the sine, cosine, and tangent logarithm and the exponential of `G`."],"id":"c081cf3b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4c22b354","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462072132,"user_tz":360,"elapsed":6,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"ba2df33f-042a-4630-d7df-4f00ad203d45"},"outputs":[{"output_type":"stream","name":"stdout","text":["G: tensor([0.0000, 0.7854, 1.5708, 2.3562])\n","Sine of G: tensor([0.0000, 0.7071, 1.0000, 0.7071])\n","Cosine of G: tensor([ 1.0000e+00,  7.0711e-01, -4.3711e-08, -7.0711e-01])\n","Tangent of G: tensor([ 0.0000e+00,  1.0000e+00, -2.2877e+07, -1.0000e+00])\n","Natural logarithm of G: tensor([   -inf, -0.2416,  0.4516,  0.8570])\n","Exponential of G: tensor([ 1.0000,  2.1933,  4.8105, 10.5507])\n"]}],"source":["import numpy as np\n","G = torch.arange(0, torch.tensor(np.pi), step=torch.tensor(np.pi / 4))\n","\n","print('G:', G)\n","print('Sine of G:',  torch.sin(G))\n","print('Cosine of G:',  torch.cos(G))\n","print('Tangent of G:',  torch.tan(G))\n","print('Natural logarithm of G:',  torch.log(G))\n","print('Exponential of G:',  torch.exp(G))\n"],"id":"4c22b354"},{"cell_type":"markdown","metadata":{"id":"629eb94b"},"source":["# <font color = 'dodgerred'>Q12: **Tensor Reduction Operations (1 Point)**\n","\n","1. Create a 3x2 tensor `H`.\n","2. Compute the sum of `H`. Print the result and shape after taking sun.\n","3. Then, perform the same operations along dimension 0 and dimension 1, printing the results and shapes.\n","4. What do you observe? How the shape changes?"],"id":"629eb94b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"729d7275","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462072132,"user_tz":360,"elapsed":5,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"22283d60-5fbc-4264-ce69-87ec74b8a59a"},"outputs":[{"output_type":"stream","name":"stdout","text":["H: tensor([[0.8592, 0.7686],\n","        [0.8398, 0.4198],\n","        [0.2565, 0.4445]])\n","\n","Shape of original Tensor H torch.Size([3, 2])\n","\n","Sum of H: tensor(3.5884)\n","Shape after Sum of H: torch.Size([])\n","\n","Sum of H along dimension 0: tensor([1.9556, 1.6329])\n","Shape after sum of H along dimension 0: torch.Size([2])\n","\n","Sum of H along dimension 1: tensor([1.6278, 1.2596, 0.7011])\n","Shape after sum of H along dimension 1: torch.Size([3])\n"]}],"source":["H = torch.rand(3, 2)\n","print('H:', H, end = \"\\n\\n\")\n","print('Shape of original Tensor H', H.shape, end = \"\\n\\n\")\n","\n","print('Sum of H:',  torch.sum(H))\n","print('Shape after Sum of H:', torch.sum(H).shape,  end = \"\\n\\n\")\n","\n","print('Sum of H along dimension 0:',  torch.sum(H, dim = 0))\n","print('Shape after sum of H along dimension 0:',  torch.sum(H, dim = 0).shape,  end = \"\\n\\n\")\n","\n","print('Sum of H along dimension 1:', torch.sum(H, dim = 1))\n","print('Shape after sum of H along dimension 1:',  torch.sum(H, dim = 1).shape)\n"],"id":"729d7275"},{"cell_type":"markdown","source":["**Provide your observations on shape changes here**\n","\n","1. Is the sum of all the scalars in the Tensor H, therefore it is a scalar.\n","\n","2. Is the sum along dimension 0 (rows), therefore it is a scalar of dimension (2,).\n","\n","3. Is the sum along dimension 1 (columns), therefore it is a scalar of dimension (3,)."],"metadata":{"id":"hfmDz2OLb8M2"},"id":"hfmDz2OLb8M2"},{"cell_type":"markdown","metadata":{"id":"4a156a3a"},"source":["# <font color = 'dodgerred'>**Q13: Working with Tensor Data Types (1 Point)**\n","\n","1. Create a tensor `I` of data type float with values `[1.0, 2.0, 3.0]`.\n","2. Convert `I` to data type int and print the result.\n","3. Explain in which scenarios it's necessary to be cautious about the data type of tensors."],"id":"4a156a3a"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"af427555","executionInfo":{"status":"ok","timestamp":1706462072132,"user_tz":360,"elapsed":4,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"2a573d7b-7b71-402e-9e02-18a965254995"},"outputs":[{"output_type":"stream","name":"stdout","text":["I: tensor([1., 2., 3.])\n","I converted to int: tensor([1, 2, 3], dtype=torch.int32)\n"]}],"source":["# Solution for Q16\n","I =  torch.tensor([1.0, 2.0, 3.0], dtype=torch.float)\n","print('I:', I)\n","I_int =  I.to(dtype=torch.int)\n","print('I converted to int:', I_int)"],"id":"af427555"},{"cell_type":"markdown","source":["**Your explanations here**\n","\n","Memory usage, precision loss and gradient computation are the reasons to be cautiuos.\n","\n"],"metadata":{"id":"9yyx5WtweGNP"},"id":"9yyx5WtweGNP"},{"cell_type":"markdown","metadata":{"id":"2TU6l0nC3EfW"},"source":["# <font color = 'dodgerred'>**Q14. Speedtest for vectorization 1.5 Points** </font>\n","\n","Your goal is to measure the speed of linear algebra operations for different levels of vectorization.\n","\n","1. Construct two matrices $A$ and $B$ with Gaussian random entries of size $1024 \\times 1024$.\n","1. Compute $C = A B$ using matrix-matrix operations and report the time. (Hint: Use torch.mm)\n","1. Compute $C = A B$, treating $A$ as a matrix but computing the result for each column of $B$ one at a time. Report the time. (hint use torch.mv inside a for loop)\n","1. Compute $C = A B$, treating $A$ and $B$ as collections of vectors. Report the time. (Hint: use torch.dot inside nested for loop)"],"id":"2TU6l0nC3EfW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkKjtX0HH2wz"},"outputs":[],"source":["## Solution 1\n","torch.manual_seed(42) # dod not chnage this\n","A = torch.randn(1024, 1024)\n","B = torch.randn(1024, 1024)"],"id":"wkKjtX0HH2wz"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSMH_j5OD2ZB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462072239,"user_tz":360,"elapsed":2,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"6ff6da76-b86f-43d2-9e9e-21e000ef5bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by matrix: 0.042911529541015625 seconds\n"]}],"source":["## Solution 2\n","start=time.time()\n","\n","C = torch.mm(A, B)\n","\n","print(\"Matrix by matrix: \" + str(time.time()-start) + \" seconds\")"],"id":"kSMH_j5OD2ZB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-tU8yGBP-Crk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462072474,"user_tz":360,"elapsed":237,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"7e70ca46-0da5-4ef7-eace-24876bbfb864"},"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by vector: 0.3060941696166992 seconds\n"]}],"source":["## Solution 3\n","C= torch.empty(1024,1024)\n","start = time.time()\n","\n","C = torch.zeros(1024, 1024)\n","for i in range(B.size(1)):\n","    C[:, i] = torch.mv(A, B[:, i])\n","\n","print(\"Matrix by vector: \" + str(time.time()-start) + \" seconds\")"],"id":"-tU8yGBP-Crk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFgJCFf6DUFK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462117128,"user_tz":360,"elapsed":44655,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"195b236d-f12d-49ef-ae13-737ba63fd795"},"outputs":[{"output_type":"stream","name":"stdout","text":["vector by vector: 44.67663264274597 seconds\n"]}],"source":["## Solution 4\n","C= torch.empty(1024,1024)\n","start = time.time()\n","\n","C = torch.zeros(1024, 1024)\n","for i in range(A.size(1)):\n","    for j in range(B.size(1)):\n","        C[i, j] = torch.dot(A[:, i], B[:, j])\n","\n","print(\"vector by vector: \" + str(time.time()-start) + \" seconds\")"],"id":"MFgJCFf6DUFK"},{"cell_type":"markdown","metadata":{"id":"TtYsJM4mJNdE"},"source":["# <font color = 'dodgerred'>**Q15 : Redo Question 14 by using GPU - 1.5 Points**"],"id":"TtYsJM4mJNdE"},{"cell_type":"markdown","metadata":{"id":"fxJ1UlTf3Efb"},"source":["<font size = 4, color = 'dodgerred'> **Using GPUs**\n","\n","How to use GPUs in Google Colab<br>\n","In Google Colab -- Go to Runtime Tab at top -- select change runtime type -- for hardware accelartor choose GPU"],"id":"fxJ1UlTf3Efb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6ilpofMIe1e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462117128,"user_tz":360,"elapsed":3,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"61eda60b-16b3-4dd0-81ad-20a00ef69a1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["# Check if GPU is availaible\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"id":"_6ilpofMIe1e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4XMhjifbJcu0"},"outputs":[],"source":["## Solution 1\n","torch.manual_seed(42)\n","A= torch.randn((1024, 1024),device=device)\n","B= torch.randn((1024, 1024),device=device)"],"id":"4XMhjifbJcu0"},{"cell_type":"code","source":["print(A)\n","print(B)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HWkK2x8cEuBP","executionInfo":{"status":"ok","timestamp":1706462222735,"user_tz":360,"elapsed":174,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"51ee66b7-efdb-4d02-891b-138babcfdea8"},"id":"HWkK2x8cEuBP","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 0.1940,  2.1614, -0.1721,  ...,  2.8564,  0.6748,  2.0562],\n","        [ 0.8234, -2.3821,  1.2520,  ...,  1.4540, -2.7733, -0.8932],\n","        [-0.4574,  0.8063,  0.1580,  ..., -0.6279,  0.7594, -2.4643],\n","        ...,\n","        [ 0.7528, -0.3422,  0.6958,  ..., -0.0805,  0.7321, -0.4877],\n","        [-0.4304, -1.8875, -0.0588,  ..., -1.7712, -0.6523, -1.0117],\n","        [ 0.1621, -0.1626,  0.8502,  ...,  1.0908, -0.7354, -0.8094]],\n","       device='cuda:0')\n","tensor([[ 7.8214e-01,  1.3969e+00, -1.8156e-01,  ...,  1.0963e+00,\n","          2.2060e+00,  4.9150e-01],\n","        [ 9.7876e-01, -1.0868e+00,  7.6596e-01,  ...,  2.0217e+00,\n","         -4.4059e-01, -1.2401e+00],\n","        [ 1.1979e+00,  1.9029e+00, -5.8293e-01,  ...,  5.8142e-01,\n","          5.5776e-01, -4.1612e-01],\n","        ...,\n","        [ 7.5334e-01, -1.7123e-01, -2.2482e+00,  ..., -9.0756e-01,\n","          6.6091e-01,  8.7813e-01],\n","        [ 1.4010e+00,  8.1821e-01, -1.3200e-03,  ..., -5.0882e-01,\n","          1.4235e+00,  8.6407e-01],\n","        [-1.1375e-01,  3.7065e-01, -3.8879e-01,  ..., -1.3477e+00,\n","          1.3918e+00,  8.7304e-01]], device='cuda:0')\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pn-ZKI7sK9Oh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462117759,"user_tz":360,"elapsed":219,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"f2e4982c-4b6f-474c-eb73-c262d54da591"},"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by matrix: 0.11477398872375488 seconds\n"]}],"source":["## Solution 2\n","start=time.time()\n","\n","C = torch.mm(A, B)\n","\n","print(\"Matrix by matrix: \" + str(time.time()-start) + \" seconds\")"],"id":"pn-ZKI7sK9Oh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcHPGEitLL8i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462117857,"user_tz":360,"elapsed":100,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"9724d30c-8632-47eb-d834-c7d5b73415b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix by vector: 0.1631183624267578 seconds\n"]}],"source":["## Solution 3\n","C= torch.empty(1024,1024, device = device)\n","start = time.time()\n","\n","C = torch.zeros(1024, 1024)\n","for i in range(B.size(1)):\n","    C[:, i] = torch.mv(A, B[:, i])\n","\n","print(\"Matrix by vector: \" + str(time.time()-start) + \" seconds\")"],"id":"GcHPGEitLL8i"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZ5LWSa2Lrdw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706462171500,"user_tz":360,"elapsed":53645,"user":{"displayName":"HARIKRISHNA DEV","userId":"02939311304673631641"}},"outputId":"444b4e97-7e7d-4e39-d241-0a156b358667"},"outputs":[{"output_type":"stream","name":"stdout","text":["vector by vector: 53.51922106742859 seconds\n"]}],"source":["## Solution 4\n","C= torch.empty(1024,1024, device = device)\n","start = time.time()\n","\n","C = torch.zeros(1024, 1024)\n","for i in range(A.size(1)):\n","    for j in range(B.size(1)):\n","        C[i, j] = torch.dot(A[:, i], B[:, j])\n","\n","print(\"vector by vector: \" + str(time.time()-start) + \" seconds\")"],"id":"wZ5LWSa2Lrdw"}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}